# -*- coding: utf-8 -*-
"""naver_news_crawling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iRtOa-RiFbUBBLrJugJqIoeovqncmbSO
"""

import os
import urllib.request
import pandas as pd
import json
import re

# 네이버 API 설정
client_id = "PoDH_g_ZdPR_qMptIdj4"  # 네이버 애플리케이션 클라이언트 ID
client_secret = "Gw3vVnnTOw"  # 네이버 애플리케이션 클라이언트 시크릿

# 검색 키워드 입력
query = urllib.parse.quote(input("보고 싶은 키워드: "))
idx = 0
display = 10  # 한 번에 가져올 데이터 수 (최대 100)
start = 1      # 시작 인덱스
end = 100    # 최대 데이터 개수
sort = "sim"   # 정렬 방식 (sim: 유사도, date: 날짜순)

# DataFrame 생성
news_df = pd.DataFrame(columns=["Title", "Original Link", "Link", "Description", "Publication Date"])

# 뉴스 데이터 가져오기
for start_idx in range(start, end, display):
    try:
        # API 요청 URL 생성
        url = f"https://openapi.naver.com/v1/search/news?query={query}" \
              f"&display={display}&start={start_idx}&sort={sort}"
        request = urllib.request.Request(url)
        request.add_header("X-Naver-Client-Id", client_id)
        request.add_header("X-Naver-Client-Secret", client_secret)

        # API 요청 및 응답 처리
        response = urllib.request.urlopen(request)
        response_body = response.read()
        response_dict = json.loads(response_body.decode('utf-8'))

        # 뉴스 아이템 처리
        items = response_dict.get('items', [])
        for item in items:
            remove_tag = re.compile('<.*?>')  # HTML 태그 제거 정규식
            title = re.sub(remove_tag, '', item.get('title', ''))
            original_link = item.get('originallink', '')
            link = item.get('link', '')
            description = re.sub(remove_tag, '', item.get('description', ''))
            pub_date = item.get('pubDate', '')
            news_df.loc[idx] = [title, original_link, link, description, pub_date]
            idx += 1

    except urllib.error.HTTPError as e:
        print(f"HTTPError 발생: {e.code} {e.reason}")
    except urllib.error.URLError as e:
        print(f"URLError 발생: {e.reason}")
    except Exception as e:
        print(f"예외 발생: {e}")

# 결과 확인
print(news_df)

news_df.to_csv("news_data.csv", index=False, encoding="utf-8-sig")

import firebase_admin
from firebase_admin import credentials, firestore
import pandas as pd

# Firebase 인증 및 Firestore 초기화
cred = credentials.Certificate("fb-test-b4125-firebase-adminsdk-wr8zo-b162570567.json")
firebase_admin.initialize_app(cred)
db = firestore.client()

# DataFrame에서 Firestore로 데이터 저장
def save_to_firestore(df, collection_name):
    collection_ref = db.collection(collection_name)
    for _, row in df.iterrows():
        doc_ref = collection_ref.document()  # Firestore 문서 ID를 자동 생성
        doc_ref.set({
            "title": row["Title"],
            "original_link": row["Original Link"],
            "link": row["Link"],
            "description": row["Description"],
            "pub_date": row["Publication Date"]
        })
        
    print(f"Data saved to Firestore collection: {collection_name}")

# 뉴스 데이터 DataFrame (예: 앞에서 만든 news_df)
news_df = pd.read_csv("news_data.csv")  # CSV로 저장된 데이터를 읽어올 경우
# 또는 news_df = ...  # 기존 스크립트에서 생성한 DataFrame 사용

# Firestore에 데이터 저장
save_to_firestore(news_df, "news_collection")

